{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "#from mtcnn.mtcnn import MTCNN\n",
    "from matplotlib.patches import Rectangle\n",
    "from keras.models import load_model\n",
    "from matplotlib.patches import Circle\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "import datetime\n",
    "import xlwt\n",
    "import xlrd\n",
    "from xlwt import Workbook \n",
    "from xlutils.copy import copy\n",
    "import time\n",
    "# from facenet_pytorch import MTCNN\n",
    "# from cv2 import dnn_superres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model of MTCNN and FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = 'facenet_keras.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=MTCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_encoder = load_model(encoder_model)\n",
    "people_dir = './people'\n",
    "encoding_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = []\n",
    "with open('coco.names','r') as f:\n",
    "    classNames = f.read().splitlines()\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsPath = \"frozen_inference_graph.pb\"\n",
    "configPath = \"ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\"\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "# path = \"LapSRN_x8.pb\"\n",
    "# sr.readModel(path)\n",
    "\n",
    "# # Set the desired model and scale to get correct pre- and post-processing\n",
    "# sr.setModel(\"lapsrn\", 8)\n",
    "\n",
    "# sr.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "# sr.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding of face using FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encode(face_encoder, face, size):\n",
    "    face = normalize(face)\n",
    "    face = cv2.resize(face, size)\n",
    "    encode = face_encoder.predict(np.expand_dims(face, axis=0))[0]\n",
    "    return encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Face for encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face(img, box):\n",
    "    [[x1, y1, width, height]] = box\n",
    "    x1, y1 ,x2,y2= int(x1), int(y1),int(width),int(height)\n",
    "    #x2, y2 = x1 + width, y1 + height\n",
    "    face = img[y1:y2, x1:x2]\n",
    "    return face, (x1, y1), (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def get_face(img, box):\n",
    "    [[x1, y1, width, height]] = box\n",
    "    x1, y1 ,x2,y2= int(x1), int(y1),int(width),int(height)\n",
    "    #x2, y2 = x1 + width, y1 + height\n",
    "    face = img[y1:y2, x1:x2]\n",
    "    return face, (x1, y1), (x2, y2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    mean, std = img.mean(), img.std()\n",
    "    return (img - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_normalizer = Normalizer('l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(a):\n",
    "    ct = datetime.datetime.now()\n",
    "    \n",
    "    ws = xlrd.open_workbook('names_list.xls',formatting_info=True)\n",
    "    sheet = ws.sheet_by_index(0)\n",
    "    wb=copy(ws)\n",
    "    names_sheet=wb.get_sheet(0)\n",
    "    row_s=sheet.nrows\n",
    "    col_s=sheet.ncols\n",
    "    \n",
    "    names_sheet.write(0,col_s,str(ct.year)+\"_\"+str(ct.month)+\"_\"+str(ct.day)+\"_\"+str(ct.hour))\n",
    "    \n",
    "    for i in range(1,row_s):   \n",
    "        \n",
    "        if sheet.cell_value(i,0) in a:\n",
    "            names_sheet.write(i, col_s,\"P\")\n",
    "                \n",
    "        else:\n",
    "                \n",
    "            names_sheet.write(i, col_s,\"A\")\n",
    "    wb.save(\"names_list.xls\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_attendance(a):\n",
    "    \n",
    "\n",
    "    ct = datetime.datetime.now()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    workbook = xlwt.Workbook()  \n",
    "\n",
    "    sheet = workbook.add_sheet(str(ct.year)+\"_\"+str(ct.month)+\"_\"+str(ct.day)) \n",
    "    sheet.write(0,0,\"Name\")\n",
    "\n",
    "\n",
    "    row = 1\n",
    "    col = 0\n",
    "    if len(a)>0:\n",
    "        for person_name in os.listdir(people_dir):\n",
    "            print(person_name)\n",
    "            print(a)\n",
    "\n",
    "            for x in range(0,len(a)):\n",
    "                if str(person_name) in a:\n",
    "                    sheet.write(row, col,     str(a[x]))\n",
    "                    sheet.write(row,col+1,\"P\")\n",
    "                    \n",
    "                else:\n",
    "                    sheet.write(row, col,     str(a[x]),)\n",
    "                    sheet.write(row,col+1,\"A\")\n",
    "                row+=1\n",
    "         \n",
    "            \n",
    "  \n",
    "        workbook.save(\"sample_class_1.xls\") \n",
    "    else:\n",
    "        sheet.write(1,0,\"No one is present\")\n",
    "        workbook.save(\"sample_class_1.xls\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved Images whhich are encoded and stored in a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person_name in os.listdir(people_dir):\n",
    "    person_dir = os.path.join(people_dir, person_name)\n",
    "    encodes = []\n",
    "    for img_name in os.listdir(person_dir):\n",
    "        img_path = os.path.join(person_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        boxes,probs = detector.detect(img)\n",
    "\n",
    "        #results = detector.detect_faces(img)\n",
    "        if boxes is not None:\n",
    "            print(boxes)\n",
    "        \n",
    "            #res = max(results, key=lambda b: b['box'][2] * b['box'][3])\n",
    "            face, _, _ = get_face(img, boxes.tolist())\n",
    "            \n",
    "            face = normalize(face)\n",
    "            face = cv2.resize(face,(160,160))\n",
    "            encode = face_encoder.predict(np.expand_dims(face, axis=0))[0]\n",
    "            encodes.append(encode)\n",
    "    if encodes:\n",
    "        encode = np.sum(encodes, axis=0)\n",
    "        encode = l2_normalizer.transform(np.expand_dims(encode, axis=0))[0]\n",
    "        encoding_dict[person_name] = encode\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_t=0.6\n",
    "confidence_t=0.99\n",
    "thres = 0.5 # Threshold to detect object\n",
    "nms_threshold = 0.2 #(0.1 to 1) 1 means no suppress , 0.1 means high suppress\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "#font = cv2.FONT_HERSHEY_COMPLEX\n",
    "Colors = np.random.uniform(0, 255, size=(len(classNames), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Face Detection and Recognition (Press q to end video stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RTSP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"rtsp_username = \"admin\"\n",
    "rtsp_password = \"admin@123\"\n",
    "##change the channel no according to the one out of 4\n",
    "rtsp = \"rtsp://\" + rtsp_username + \":\" + rtsp_password + \"@192.168.11.110:554/Streaming/channels/\" + channel + \"02\" #change the IP to suit yours\n",
    "cap = cv2.VideoCapture()\n",
    "cap.open(rtsp)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video =cv2.VideoCapture('rtsp://admin:admin@192.168.1.240/1') \n",
    "#https://stackoverflow.com/questions/49978705/access-ip-camera-in-python-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#video =cv2.VideoCapture(0)\n",
    "present_candidates=[]\n",
    "fps_start_time = datetime.datetime.now()\n",
    "fps = 0\n",
    "total_frames = 0\n",
    "\n",
    "\n",
    "sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "path = \"ESPCN_x2.pb\"\n",
    "#path = \"LapSRN_x2.pb\"\n",
    "sr.readModel(path)\n",
    "\n",
    "# Set the desired model and scale to get correct pre- and post-processing\n",
    "sr.setModel(\"espcn\", 2)\n",
    "#sr.setModel(\"lapsrn\", 2)\n",
    "\n",
    "#d = IPython.display.display(\"\", display_id=1)\n",
    "\n",
    "while True:\n",
    "    check,frame=video.read()\n",
    "    #frame=sr.upsample(frame)\n",
    "    total_frames = total_frames + 1\n",
    "\n",
    "    faces,_=detector.detect(frame)\n",
    "    \n",
    "    if faces is not None:\n",
    "        for person in faces:\n",
    "            #print(person)\n",
    "            bounding_box=person\n",
    "            #keypoints=person[\"keypoints\"]\n",
    "#             if person['confidence'] < confidence_t:\n",
    "#                 continue\n",
    "            face, pt_1, pt_2 = get_face(frame, [bounding_box])\n",
    "            encode = get_encode(face_encoder, face,(160,160))\n",
    "            encode = l2_normalizer.transform(encode.reshape(1, -1))[0]\n",
    "            name = 'unknown'\n",
    "            \n",
    "            \n",
    "            distance = float(\"inf\")\n",
    "            \n",
    "            \n",
    "            for (db_name, db_enc) in encoding_dict.items():\n",
    "        \n",
    "                dist = cosine(db_enc, encode)\n",
    "          \n",
    "                if dist < recognition_t and dist < distance:\n",
    "                \n",
    "                    name = db_name\n",
    "                    distance = dist\n",
    "                    if name not in present_candidates:\n",
    "                        present_candidates.append(name)\n",
    "                    \n",
    "                    \n",
    "            if name == 'unknown':\n",
    "                cv2.rectangle(frame, pt_1, pt_2, (0, 0, 255), 2)\n",
    "                cv2.putText(frame,name, pt_1, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)\n",
    "                \n",
    "            else:\n",
    "                cv2.rectangle(frame, pt_1, pt_2, (0, 255, 0), 2)\n",
    "                cv2.putText(frame,name + f'__{distance:.2f}', (pt_1[0], pt_1[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                        (0, 200, 200), 2)\n",
    "                \n",
    "    fps_end_time = datetime.datetime.now()\n",
    "    time_diff = fps_end_time - fps_start_time\n",
    "    if time_diff.seconds == 0:\n",
    "        fps = 0.0\n",
    "    else:\n",
    "        fps = (total_frames / time_diff.seconds)\n",
    "\n",
    "    fps_text = \"FPS: {:.2f}\".format(fps)\n",
    "\n",
    "    cv2.putText(frame, fps_text, (5, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "       \n",
    "    cv2.imshow('frame',frame)  \n",
    "    print(\"check\")\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "          break\n",
    "            \n",
    "            \n",
    "            \n",
    "video.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for no,obj in enumerate(classIds):\n",
    "    if obj==[1]:\n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "print(count)#####Number of people detected "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snap based Face Detection and recognition (Press Spacebar to take a snap and Escape to end the stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"video1 =cv2.VideoCapture('rtsp://admin:admin@192.168.1.240/1') \n",
    "#https://stackoverflow.com/questions/49978705/access-ip-camera-in-python-opencv\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "present_candidates_1=[]\n",
    "img_counter=0\n",
    "fps_start_time = datetime.datetime.now()\n",
    "fps = 0\n",
    "total_frames = 0\n",
    "while True:\n",
    "    \n",
    "    check,frame=video1.read()\n",
    "    total_frames = total_frames + 1\n",
    "    frame=sr.upsample(frame)\n",
    "    \n",
    "    fps_end_time = datetime.datetime.now()\n",
    "    time_diff = fps_end_time - fps_start_time\n",
    "    if time_diff.seconds == 0:\n",
    "        fps = 0.0\n",
    "    else:\n",
    "        fps = (total_frames / time_diff.seconds)\n",
    "\n",
    "    fps_text = \"FPS: {:.2f}\".format(fps)\n",
    "\n",
    "    cv2.putText(frame, fps_text, (5, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "    \n",
    "    cv2.imshow(\"SS\",frame)\n",
    "    k=cv2.waitKey(1)\n",
    "    \n",
    "    if k%256 == 27:\n",
    "        print(\"Escape\")\n",
    "        break\n",
    "        \n",
    "    elif k%256==32:\n",
    "        faces=detector.detect_faces(frame)\n",
    "        if faces !=[]:\n",
    "            for person in faces:\n",
    "                bounding_box=person[\"box\"]\n",
    "                keypoints=person[\"keypoints\"]\n",
    "    #             if person['confidence'] < confidence_t:\n",
    "    #                 continue\n",
    "                face, pt_1, pt_2 = get_face(frame, person['box'])\n",
    "                encode = get_encode(face_encoder, face,(160,160))\n",
    "                encode = l2_normalizer.transform(encode.reshape(1, -1))[0]\n",
    "                name = 'unknown'\n",
    "\n",
    "\n",
    "                distance = float(\"inf\")\n",
    "\n",
    "\n",
    "                for (db_name, db_enc) in encoding_dict.items():\n",
    "\n",
    "                    dist = cosine(db_enc, encode)\n",
    "\n",
    "                    if dist < recognition_t and dist < distance:\n",
    "\n",
    "                        name = db_name\n",
    "                        distance = dist\n",
    "                        if name not in present_candidates_1:\n",
    "                            present_candidates_1.append(name)\n",
    "\n",
    "                if name == 'unknown':\n",
    "                    cv2.rectangle(frame, pt_1, pt_2, (0, 0, 255), 2)\n",
    "                    cv2.putText(frame,name, pt_1, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)\n",
    "\n",
    "                else:\n",
    "                    cv2.rectangle(frame, pt_1, pt_2, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame,name + f'__{distance:.2f}', (pt_1[0], pt_1[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                            (0, 200, 200), 2)\n",
    "                    \n",
    "        \n",
    "                    \n",
    "        img_name=\"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name,frame)\n",
    "        print(\"Screenshot\")\n",
    "        img_counter+=1\n",
    "\n",
    "video1.release()\n",
    "cv2.destroyAllWindows()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidates present (Live video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidates present (Snap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#present_candidates_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export(present_candidates_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export(present_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(faces)#Number of faces detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
