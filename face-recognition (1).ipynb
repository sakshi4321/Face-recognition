{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install xlwt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install xlrd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install opencv-contrib-python==4.5.1.48","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install facenet-pytorch\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install xlutils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install mtcnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nimport xlwt\nimport xlrd\nfrom xlwt import Workbook \nfrom matplotlib import pyplot\n#from mtcnn.mtcnn import MTCNN\nfrom matplotlib.patches import Rectangle\nfrom keras.models import load_model\nfrom matplotlib.patches import Circle\nimport cv2\nimport numpy as np\nfrom sklearn.preprocessing import Normalizer\nfrom scipy.spatial.distance import cosine\nimport os\nfrom xlutils.copy import copy\nfrom facenet_pytorch import MTCNN\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(f'Running on device: {device}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.compat.v1.debugging.set_log_device_placement(True)\nprint(tf.config.list_physical_devices('GPU'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.test.gpu_device_name()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** TPU **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# detect and init the TPU\n#tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\n#tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#with tpu_strategy.scope():\nencoder_model = '../input/facenet-keras/facenet_keras.h5'\n\ndetector=MTCNN(keep_all=False, device='cuda:0')\n#detector=MTCNN()\nface_encoder = load_model(encoder_model)\n\npeople_dir = '../input/photos'\nencoding_dict = dict()\n\n\"\"\"### Encoding of face using FaceNet\"\"\"\n\ndef get_encode(face_encoder, face, size):\n    face = normalize(face)\n    face = cv2.resize(face, size)\n    encode = face_encoder.predict(np.expand_dims(face, axis=0))[0]\n    return encode\n\n\"\"\"### Extract Face for encoding\"\"\"\n\ndef get_face(img, box):\n    [[x1, y1, width, height]] = box\n    x1, y1 ,x2,y2= int(x1), int(y1),int(width),int(height)\n    #x2, y2 = x1 + width, y1 + height\n    face = img[y1:y2, x1:x2]\n    return face, (x1, y1), (x2, y2)\n\"\"\"def get_face(img, box):\n    x1, y1, width, height = box\n    x1, y1 = abs(x1), abs(y1)\n    x2, y2 = x1 + width, y1 + height\n    face = img[y1:y2, x1:x2]\n    return face, (x1, y1), (x2, y2)\"\"\"\n\n\ndef normalize(img):\n    mean, std = img.mean(), img.std()\n    return (img - mean) / std\n\nl2_normalizer = Normalizer('l2')\n\n### collect daywise attendance by checking through a list of ppl\ndef export(a):\n\n    ct = datetime.datetime.now()\n    ws = xlrd.open_workbook('../input/nnnnnnn/names_list.xls',formatting_info=True)\n    sheet = ws.sheet_by_index(0)\n    wb=copy(ws)\n    names_sheet=wb.get_sheet(0)\n    row_s=sheet.nrows\n    col_s=sheet.ncols\n    names_sheet.write(0,col_s,str(ct.year)+\"_\"+str(ct.month)+\"_\"+str(ct.day)+\"_\"+str(ct.hour))\n    for i in range(1,row_s):\n\n        if sheet.cell_value(i,0) in a:\n            names_sheet.write(i, col_s,\"P\")\n\n        else:  \n            names_sheet.write(i, col_s,\"A\")\n\n\n    wb.save(\"../input/nnnnnnn/names_list.xls\") \n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#free_gpu_cache()\nwith tpu_strategy.scope():\n    for person_name in os.listdir(people_dir):\n        person_dir = os.path.join(people_dir, person_name)\n        encodes = []\n        for img_name in os.listdir(person_dir):\n            img_path = os.path.join(person_dir, img_name)\n            img = cv2.imread(img_path)\n\n            boxes,probs = detector.detect(img)\n            #print(boxes)\n            results = detector.detect_faces(img)\n            if len(boxes)>0:\n\n                #res = max(results, key=lambda b: b['box'][2] * b['box'][3])\n                #print(res)\n                face, _, _ = get_face(img, boxes)\n                #plt.imshow(face)\n                face = normalize(face)\n                face = cv2.resize(face,(160,160))\n                encode = face_encoder.predict(np.expand_dims(face, axis=0))[0]\n                encodes.append(encode)\n        if encodes:\n            encode = np.sum(encodes, axis=0)\n            encode = l2_normalizer.transform(np.expand_dims(encode, axis=0))[0]\n            encoding_dict[person_name] = encode\n        #free_gpu_cache()\n\n    recognition_t=0.6\n    confidence_t=0.99","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#free_gpu_cache()\nvideo =cv2.VideoCapture('../input/videoo/WIN_20210324_18_59_11_Pro.mp4')\npresent_candidates=[]\n\n#sr = cv2.dnn_superres.DnnSuperResImpl_create()\n\n#path = \"../input/nnnnnnn/LapSRN_x8.pb\"\n#sr.readModel(path)\n#sr.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n#sr.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n# Set the desired model and scale to get correct pre- and post-processing\n#sr.setModel(\"lapsrn\", 8)\n\ncheck=True\n\n\nif check:\n    check,frame=video.read()\n    \n    frame=sr.upsample(frame)\n    \n\n\n\n    faces=detector.detect_faces(frame)\n    print(\"chh\")\n    \n    if faces !=[]:\n        for person in faces:\n            bounding_box=person[\"box\"]\n            keypoints=person[\"keypoints\"]\n#             if person['confidence'] < confidence_t:\n#                 continue\n            face, pt_1, pt_2 = get_face(frame, person['box'])\n            encode = get_encode(face_encoder, face,(160,160))\n            encode = l2_normalizer.transform(encode.reshape(1, -1))[0]\n            name = 'unknown'\n\n\n            distance = float(\"inf\")\n\n\n            for (db_name, db_enc) in encoding_dict.items():\n\n                dist = cosine(db_enc, encode)\n\n                if dist < recognition_t and dist < distance:\n\n                    name = db_name\n                    distance = dist\n                    if name not in present_candidates:\n                        present_candidates.append(name)\n\n\n            if name == 'unknown':\n                cv2.rectangle(frame, pt_1, pt_2, (0, 0, 255), 2)\n                cv2.putText(frame,name, pt_1, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1)\n\n            else:\n                cv2.rectangle(frame, pt_1, pt_2, (0, 255, 0), 2)\n                cv2.putText(frame,name + f'__{distance:.2f}', (pt_1[0], pt_1[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 1,\n                        (0, 200, 200), 2)\n\n            #free_gpu_cache()\n    print(present_candidates)\n    \n\n\n\n\n    \n    #cv2.waitkey(0)\n\n        #if cv2.waitKey(5) & 0xFF == ord('q'):\n              #break\n\n\n\n#video.release()\n#cv2.destroyAllWindows()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}